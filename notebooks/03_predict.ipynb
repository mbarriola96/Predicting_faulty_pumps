{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Python Script, we will apply all the data transformations that were done in the 01_data_preprocessing python script on the test dataset. Moreover, we will also transform the test dataset with the best decision tree classifier that was created in the 02_model_creation. With all this, we will be able to obtain the predicted values and determine whether a pump will be functional or non-functional "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will use the test dataset given to us from DrivenData called: Test_set_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH_Test_set_values = \"../Data/Test_set_values.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_funder(funder):\n",
    "    \"\"\"\n",
    "    Categorizes a funder name into specific groups based on keywords.\n",
    "    \n",
    "    Args:\n",
    "    funder (str): A string representing the name of the funder to categorize.\n",
    "    \n",
    "    Returns:\n",
    "    str: A category name representing the type of organization the funder belongs to.\n",
    "    \n",
    "    This function takes a funder name, converts it to lowercase, removes leading/trailing spaces, \n",
    "    and categorizes it into predefined groups like 'Government', 'Religious Organizations', 'NGO',\n",
    "    'International Aid', 'Private Companies', or 'Individual/Other' based on keywords found within the name.\n",
    "    \"\"\"\n",
    "    funder = funder.lower().strip()  # convert to lowercase and strip whitespaces to standardize\n",
    "    if any(x in funder for x in ['government','ministry','gov','minis']): \n",
    "        return 'Government'\n",
    "    elif any(x in funder for x in ['church', 'muslim','mus', 'islamic','islam','catholic', 'rc']):\n",
    "        return 'Religious Organizations'\n",
    "    elif any(x in funder for x in ['ngo', 'foundation', 'fund', 'trust', 'society','socie']):\n",
    "        return 'NGO'\n",
    "    elif any(x in funder for x in ['international','internatio', 'un', 'world bank']):\n",
    "        return 'International Aid'\n",
    "    elif any(x in funder for x in ['ltd', 'company','compa', 'group', 'enterprise']):\n",
    "        return 'Private Companies'\n",
    "    else:\n",
    "        return 'Individual/Other'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_installer(installer):\n",
    "    \"\"\"\n",
    "    Categorizes an installer name into specific groups based on keywords.\n",
    "\n",
    "    Args:\n",
    "    installer (str): A string representing the name of the installer to categorize.\n",
    "\n",
    "    Returns:\n",
    "    str: A category name representing the type of entity the installer belongs to.\n",
    "\n",
    "    This function processes an installer name by converting it to lowercase and removing\n",
    "    any leading/trailing whitespace. It categorizes the name into predefined groups such as \n",
    "    'DWE', 'Government', 'Community', 'NGO', 'Private Company', 'Institutional', or 'Other' \n",
    "    based on specific keywords present in the installer's name. This helps in standardizing \n",
    "    installer data for better analysis and insight extraction.\n",
    "    \"\"\"\n",
    "    installer = installer.lower().strip()  # convert to lowercase and strip whitespaces to standardize\n",
    "    if 'dw' in installer:\n",
    "        return 'DWE'\n",
    "    elif any(x in installer for x in ['government', 'govt', 'gove']):\n",
    "        return 'Government'\n",
    "    elif any(x in installer for x in ['resource']):\n",
    "        return 'Other'\n",
    "    elif any(x in installer for x in ['community', 'villagers', 'village','commu']):\n",
    "        return 'Community'\n",
    "    elif any(x in installer for x in ['ngo', 'unicef', 'foundat']):\n",
    "        return 'NGO'\n",
    "    elif 'company' in installer or 'contractor' in installer:\n",
    "        return 'Private Company'\n",
    "    elif any(x in installer for x in ['school','schoo','church', 'rc']):\n",
    "        return 'Institutional'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_scheme_management(value):\n",
    "    \"\"\"\n",
    "    Categorizes scheme management types into broader, more generalized groups.\n",
    "\n",
    "    Args:\n",
    "    value (str): A string representing the scheme management type to categorize.\n",
    "\n",
    "    Returns:\n",
    "    str: A generalized category name representing the type of scheme management.\n",
    "\n",
    "    This function takes a specific scheme management type and categorizes it into \n",
    "    more generalized groups such as 'Government', 'Community', 'Private Sector', \n",
    "    'Water Board', or 'Other'. This categorization aids in simplifying the analysis \n",
    "    and understanding of the data by reducing the number of distinct categories, \n",
    "    making trends and patterns more discernible.\n",
    "    \"\"\"\n",
    "    if value in ['VWC', 'Water authority', 'Parastatal']:\n",
    "        return 'Government'\n",
    "    elif value in ['WUG', 'WUA']:\n",
    "        return 'Community'\n",
    "    elif value in ['Company', 'Private operator']:\n",
    "        return 'Private Sector'\n",
    "    elif value == 'Water Board':\n",
    "        return 'Water Board'  # Retain this as a separate category if distinct characteristics are important\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans a text string by converting to lowercase, removing non-alphanumeric characters (excluding numbers),\n",
    "    and replacing multiple spaces with a single space. If the input is solely numeric, it returns the input as is.\n",
    "\n",
    "    Args:\n",
    "    text (str or NaN): The text to be cleaned; can be a string, numeric, or NaN for missing values.\n",
    "\n",
    "    Returns:\n",
    "    str or NaN: The cleaned text, with all characters in lowercase, non-alphanumeric characters removed (excluding numbers),\n",
    "                and multiple spaces collapsed to a single space, or the original text if input was numeric or NaN if input was NaN.\n",
    "\n",
    "    This function standardizes a text string by making it lowercase, stripping out any characters that are not letters or spaces,\n",
    "    and then replacing sequences of spaces with a single space, facilitating uniform data processing and analysis. If the input\n",
    "    is numeric, it is assumed to be standardized already and is returned without modification.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    if isinstance(text, (int, float)):  # Check if the input is numeric\n",
    "        return text\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = ''.join(char for char in text if char.isalpha() or char.isspace())  # Remove special characters and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>Dmdd</td>\n",
       "      <td>1996</td>\n",
       "      <td>DMDD</td>\n",
       "      <td>35.290799</td>\n",
       "      <td>-4.059696</td>\n",
       "      <td>Dinamu Secondary School</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-04</td>\n",
       "      <td>Government Of Tanzania</td>\n",
       "      <td>1569</td>\n",
       "      <td>DWE</td>\n",
       "      <td>36.656709</td>\n",
       "      <td>-3.309214</td>\n",
       "      <td>Kimnyak</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.767863</td>\n",
       "      <td>-5.004344</td>\n",
       "      <td>Puma Secondary</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>never pay</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>Finn Water</td>\n",
       "      <td>267</td>\n",
       "      <td>FINN WATER</td>\n",
       "      <td>38.058046</td>\n",
       "      <td>-9.418672</td>\n",
       "      <td>Kwa Mzee Pange</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2013-03-27</td>\n",
       "      <td>Bruder</td>\n",
       "      <td>1260</td>\n",
       "      <td>BRUDER</td>\n",
       "      <td>35.006123</td>\n",
       "      <td>-10.950412</td>\n",
       "      <td>Kwa Mzee Turuka</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>monthly</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded                  funder  gps_height  \\\n",
       "0  50785         0.0    2013-02-04                    Dmdd        1996   \n",
       "1  51630         0.0    2013-02-04  Government Of Tanzania        1569   \n",
       "2  17168         0.0    2013-02-01                     NaN        1567   \n",
       "3  45559         0.0    2013-01-22              Finn Water         267   \n",
       "4  49871       500.0    2013-03-27                  Bruder        1260   \n",
       "\n",
       "    installer  longitude   latitude                 wpt_name  num_private  \\\n",
       "0        DMDD  35.290799  -4.059696  Dinamu Secondary School            0   \n",
       "1         DWE  36.656709  -3.309214                  Kimnyak            0   \n",
       "2         NaN  34.767863  -5.004344           Puma Secondary            0   \n",
       "3  FINN WATER  38.058046  -9.418672           Kwa Mzee Pange            0   \n",
       "4      BRUDER  35.006123 -10.950412          Kwa Mzee Turuka            0   \n",
       "\n",
       "   ... payment_type water_quality quality_group      quantity  quantity_group  \\\n",
       "0  ...    never pay          soft          good      seasonal        seasonal   \n",
       "1  ...    never pay          soft          good  insufficient    insufficient   \n",
       "2  ...    never pay          soft          good  insufficient    insufficient   \n",
       "3  ...      unknown          soft          good           dry             dry   \n",
       "4  ...      monthly          soft          good        enough          enough   \n",
       "\n",
       "                 source           source_type  source_class  \\\n",
       "0  rainwater harvesting  rainwater harvesting       surface   \n",
       "1                spring                spring   groundwater   \n",
       "2  rainwater harvesting  rainwater harvesting       surface   \n",
       "3          shallow well          shallow well   groundwater   \n",
       "4                spring                spring   groundwater   \n",
       "\n",
       "      waterpoint_type waterpoint_type_group  \n",
       "0               other                 other  \n",
       "1  communal standpipe    communal standpipe  \n",
       "2               other                 other  \n",
       "3               other                 other  \n",
       "4  communal standpipe    communal standpipe  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = pd.read_csv(INPUT_PATH_Test_set_values)\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Apply the same data transformations on df_predict as the ones done in 00_data_understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.1 Applying transformation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column 'funder'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling NaN values with a filler string like 'Unknown'\n",
    "df_predict['funder'] = df_predict['funder'].fillna('Unknown').astype(str)\n",
    "\n",
    "# Apply the mapping function to the 'funder' column\n",
    "df_predict['funder_type'] = df_predict['funder'].apply(categorize_funder)\n",
    "\n",
    "# Check the categorized data\n",
    "print(df_predict['funder_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column 'installer'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling NaN values with a filler string like 'Unknown'\n",
    "df_train_merge['installer'] = df_train_merge['installer'].fillna('Unknown').astype(str)\n",
    "\n",
    "# Apply the mapping function to the 'installer' column\n",
    "df_train_merge['installer_type'] = df_train_merge['installer'].apply(categorize_installer)\n",
    "\n",
    "# Now you can check your categorized data\n",
    "print(df_train_merge['installer_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column 'scheme_management_grouped'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the grouping function to the 'scheme_management' column\n",
    "df_predict['scheme_management_grouped'] = df_predict['scheme_management'].apply(group_scheme_management)\n",
    "\n",
    "# Check the new value counts to see the grouped data\n",
    "print(df_train_merge['scheme_management_grouped'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.2 Converting data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'construction_year' to object\n",
    "df_predict['construction_year'] = df_predict['construction_year'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n",
       "       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n",
       "       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n",
       "       'ward', 'population', 'public_meeting', 'recorded_by',\n",
       "       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n",
       "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
       "       'management', 'management_group', 'payment', 'payment_type',\n",
       "       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n",
       "       'source', 'source_type', 'source_class', 'waterpoint_type',\n",
       "       'waterpoint_type_group', 'scheme_management_grouped'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 Drop unnecesary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_column_list = ['scheme_name', 'num_private', 'wpt_name', 'subvillage', 'lga', 'ward', 'recorded_by','extraction_type_group',\n",
    "                    'extraction_type', 'management', 'payment', 'water_quality', 'quantity', 'source', 'source_class',\n",
    "                    'waterpoint_type_group', 'date_recorded','funder','installer','scheme_management',\n",
    "                    'longitude','latitude','region_code','district_code','construction_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 Cleaning the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the cleaning function to each object-type column in the DataFrame\n",
    "for col in df_predict.select_dtypes(include='object').columns:\n",
    "    df_predict[col] = df_predict[col].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Fillna with the modes calculated in 01_data_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        0.000000\n",
       "amount_tsh                0.000000\n",
       "date_recorded             0.000000\n",
       "funder                    5.851852\n",
       "gps_height                0.000000\n",
       "installer                 5.905724\n",
       "longitude                 0.000000\n",
       "latitude                  0.000000\n",
       "wpt_name                  0.000000\n",
       "num_private               0.000000\n",
       "basin                     0.000000\n",
       "subvillage                0.666667\n",
       "region                    0.000000\n",
       "region_code               0.000000\n",
       "district_code             0.000000\n",
       "lga                       0.000000\n",
       "ward                      0.000000\n",
       "population                0.000000\n",
       "public_meeting            0.000000\n",
       "recorded_by               0.000000\n",
       "scheme_management         6.525253\n",
       "scheme_name              47.757576\n",
       "permit                    0.000000\n",
       "construction_year         0.000000\n",
       "extraction_type           0.000000\n",
       "extraction_type_group     0.000000\n",
       "extraction_type_class     0.000000\n",
       "management                0.000000\n",
       "management_group          0.000000\n",
       "payment                   0.000000\n",
       "payment_type              0.000000\n",
       "water_quality             0.000000\n",
       "quality_group             0.000000\n",
       "quantity                  0.000000\n",
       "quantity_group            0.000000\n",
       "source                    0.000000\n",
       "source_type               0.000000\n",
       "source_class              0.000000\n",
       "waterpoint_type           0.000000\n",
       "waterpoint_type_group     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_predict.isna().sum()/len(df_predict))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the python script 01_data_preprocessing we know that public_meeting_mode is 1.0 and the permit_mode is 1.0. So we are going to directly fill the NaNs of public_meeting and of permit with the value 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fillna in column 'public_meeting'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict['public_meeting'].fillna(1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fillna in column 'permit'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict['permit'].fillna(1.0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that there are no more null-values left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_predict.isna().sum()/len(df_predict))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Doing target enconder on the categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply a one hot encoder for the categorical columns that have 6 or less categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture categorical columns from X_train for encoding\n",
    "categorical_columns = df_predict.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Initialize one hot encoder\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "# Encoding the categorical columns in df_predict\n",
    "for col in categorical_columns:\n",
    "    if df_predict[col].nunique() <= 6:\n",
    "        # Apply OneHotEncoder for columns with 6 or fewer unique values\n",
    "        df_predict = pd.get_dummies(df_predict, columns=[col], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call in the saved fits (for the categorical columns that have more than 6 categories) applied to the categorical columns in the 01_data_preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column 'basin'\n",
    "basin_pickle = pickle.load(open('basin_target_encoder.pickle', 'rb'))\n",
    "df_predict['basin'] = basin_pickle.transform(df_predict['basin'])\n",
    "\n",
    "# Column 'extraction_type_class'\n",
    "extraction_type_class_pickle = pickle.load(open('extraction_type_class_target_encoder.pickle', 'rb'))\n",
    "df_predict['extraction_type_class'] = extraction_type_class_pickle.transform(df_predict['extraction_type_class'])\n",
    "\n",
    "# Column 'installer_type'\n",
    "installer_type_pickle = pickle.load(open('installer_type_target_encoder.pickle', 'rb'))\n",
    "df_predict['installer_type'] = installer_type_pickle.transform(df_predict['installer_type'])\n",
    "\n",
    "# Column 'payment_type'\n",
    "payment_type_pickle = pickle.load(open('payment_type_target_encoder.pickle', 'rb'))\n",
    "df_predict['payment_type'] = payment_type_pickle.transform(df_predict['payment_type'])\n",
    "\n",
    "# Column 'region_target'\n",
    "region_target_pickle = pickle.load(open('region_target_encoder.pickle', 'rb'))\n",
    "df_predict['region_target'] = region_target_pickle.transform(df_predict['region_target'])\n",
    "\n",
    "# Column 'source_type'\n",
    "source_type_pickle = pickle.load(open('source_type_target_encoder.pickle', 'rb'))\n",
    "df_predict['source_type'] = source_type_pickle.transform(df_predict['source_type'])\n",
    "\n",
    "# Column 'waterpoint_type'\n",
    "waterpoint_type_pickle = pickle.load(open('waterpoint_type_target_encoder.pickle', 'rb'))\n",
    "df_predict['waterpoint_type'] = waterpoint_type_pickle.transform(df_predict['waterpoint_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Dealing with numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's call in the saved fits applied to the numerical columns in the 01_data_preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture numerical columns\n",
    "numerical_columns = df_predict.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Numerical Columns\n",
    "numerical_columns_pickle = pickle.load(open('numerical_columns_scaler.pickle', 'rb'))\n",
    "df_predict[numerical_columns] = numerical_columns_pickle.transform(df_predict[numerical_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Apply the Decision Tree Classifier created in 02_model_creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "best_tree_pickle = pickle.load(open('best_tree.pickle', 'rb'))\n",
    "df_predict['status_group'] = best_tree_pickle.predict_proba(df_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

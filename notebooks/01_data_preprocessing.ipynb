{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the descriptive and exploratory analysis done in notebook 00_data_understanding, this Python Script will work on preprocessing the data, preparing it so that we can then work on the model training in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file will use the df_train_transform excel sheet created in the previous notebook: 00_data_understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Import the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>population</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>public_meeting</th>\n",
       "      <th>permit</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source_type</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>scheme_management_grouped</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>109</td>\n",
       "      <td>lake nyasa</td>\n",
       "      <td>iringa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>usergroup</td>\n",
       "      <td>annually</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>government</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>280</td>\n",
       "      <td>lake victoria</td>\n",
       "      <td>mara</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>usergroup</td>\n",
       "      <td>never pay</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>other</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>686</td>\n",
       "      <td>250</td>\n",
       "      <td>pangani</td>\n",
       "      <td>manyara</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>usergroup</td>\n",
       "      <td>per bucket</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>government</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>58</td>\n",
       "      <td>ruvuma southern coast</td>\n",
       "      <td>mtwara</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>submersible</td>\n",
       "      <td>usergroup</td>\n",
       "      <td>never pay</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>borehole</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>government</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>lake victoria</td>\n",
       "      <td>kagera</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gravity</td>\n",
       "      <td>other</td>\n",
       "      <td>never pay</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>other</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount_tsh  gps_height  population                  basin   region  \\\n",
       "0      6000.0        1390         109             lake nyasa   iringa   \n",
       "1         0.0        1399         280          lake victoria     mara   \n",
       "2        25.0         686         250                pangani  manyara   \n",
       "3         0.0         263          58  ruvuma southern coast   mtwara   \n",
       "4         0.0           0           0          lake victoria   kagera   \n",
       "\n",
       "   public_meeting  permit extraction_type_class management_group payment_type  \\\n",
       "0             1.0     0.0               gravity        usergroup     annually   \n",
       "1             NaN     1.0               gravity        usergroup    never pay   \n",
       "2             1.0     1.0               gravity        usergroup   per bucket   \n",
       "3             1.0     1.0           submersible        usergroup    never pay   \n",
       "4             1.0     1.0               gravity            other    never pay   \n",
       "\n",
       "  quality_group quantity_group           source_type  \\\n",
       "0          good         enough                spring   \n",
       "1          good   insufficient  rainwater harvesting   \n",
       "2          good         enough                   dam   \n",
       "3          good            dry              borehole   \n",
       "4          good       seasonal  rainwater harvesting   \n",
       "\n",
       "               waterpoint_type scheme_management_grouped    status_group  \n",
       "0           communal standpipe                government      functional  \n",
       "1           communal standpipe                     other      functional  \n",
       "2  communal standpipe multiple                government      functional  \n",
       "3  communal standpipe multiple                government  non functional  \n",
       "4           communal standpipe                     other      functional  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('df_train_transform.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Dealing with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amount_tsh                   0.000000\n",
       "gps_height                   0.000000\n",
       "population                   0.000000\n",
       "basin                        0.000000\n",
       "region                       0.000000\n",
       "public_meeting               5.612795\n",
       "permit                       5.144781\n",
       "extraction_type_class        0.000000\n",
       "management_group             0.000000\n",
       "payment_type                 0.000000\n",
       "quality_group                0.000000\n",
       "quantity_group               0.000000\n",
       "source_type                  0.000000\n",
       "waterpoint_type              0.000000\n",
       "scheme_management_grouped    0.000000\n",
       "status_group                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For train data\n",
    "(df.isna().sum()/len(df))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column 'public_meeting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.909838\n",
       "0.0    0.090162\n",
       "Name: public_meeting, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"public_meeting\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    0.914899\n",
      "0.0    0.085101\n",
      "Name: public_meeting, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Given that the null values are only 6%, lets replace them with the mode\n",
    "\n",
    "# Calculate the mode of the 'public_meeting' column\n",
    "permit_mode = df['public_meeting'].mode()[0]\n",
    "\n",
    "# Fill missing values in 'public_meeting' with the mode\n",
    "df['public_meeting'].fillna(permit_mode, inplace=True)\n",
    "\n",
    "# Verify if all NA values are filled\n",
    "print(df['public_meeting'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column 'permit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.68955\n",
       "0.0    0.31045\n",
       "Name: permit, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"permit\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    0.705522\n",
      "0.0    0.294478\n",
      "Name: permit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Given that the null values are only 5%, lets replace them with the mode\n",
    "\n",
    "# Calculate the mode of the 'permit' column\n",
    "permit_mode = df['permit'].mode()[0]\n",
    "\n",
    "# Fill missing values in 'permit' with the mode\n",
    "df['permit'].fillna(permit_mode, inplace=True)\n",
    "\n",
    "# Verify if all NA values are filled\n",
    "print(df['permit'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Class Imbalance checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution of status_group:\n",
      "functional                 0.543081\n",
      "non functional             0.384242\n",
      "functional needs repair    0.072677\n",
      "Name: status_group, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution in y_train\n",
    "print(\"Class distribution of status_group:\")\n",
    "print(df['status_group'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decide to group together into a same class functional needs repair and functional. In this way, we have a binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in y_train after replacement:\n",
      "functional        0.615758\n",
      "non functional    0.384242\n",
      "Name: status_group, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Replace 'functional needs repair' with 'functional'\n",
    "df['status_group'] = df['status_group'].replace('functional needs repair', 'functional')\n",
    "\n",
    "# Verify changes by checking the class distribution again in y_train and y_test\n",
    "print(\"Class distribution in y_train after replacement:\")\n",
    "print(df['status_group'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Define predictor and target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['status_group']\n",
    "X = df.drop('status_group', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Do a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Doing target enconder on the categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that most of the categorical columns have more than 6 values, we are going to perfom a target enconder on these categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'status_group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'status_group'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-061041b9af73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert 'status_group' to a categorical type with a numeric representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status_group'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'object'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status_group'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'status_group'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Capture the target before it's dropped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'status_group'"
     ]
    }
   ],
   "source": [
    "# Convert 'status_group' to a categorical type with a numeric representation\n",
    "if y_train['status_group'].dtype == 'object':\n",
    "    y_train['status_group'] = y_train['status_group'].astype('category').cat.codes\n",
    "    \n",
    "# Capture the target before it's dropped\n",
    "y = y_train['status_group']\n",
    "    \n",
    "# Capture categorical columns\n",
    "categorical_columns = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Initialize the TargetEncoder\n",
    "encoder = TargetEncoder(cols=categorical_columns)\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "encoder.fit(X_train[categorical_columns], y)\n",
    "            \n",
    "X_train[categorical_columns] = encoder.transform(X_train[categorical_columns])\n",
    "\n",
    "# Display the DataFrame to check the results\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'status_group' to a categorical type with a numeric representation\n",
    "if X_test['status_group'].dtype == 'object':\n",
    "    X_test['status_group'] = X_test['status_group'].astype('category').cat.codes\n",
    "    \n",
    "# Capture the target before it's dropped\n",
    "y = X_test['status_group']\n",
    "\n",
    "# Drops the target column from the DataFrame\n",
    "X = X_test.drop('status_group', axis=1)\n",
    "    \n",
    "# Capture categorical columns\n",
    "categorical_columns = X_test.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Initialize the TargetEncoder\n",
    "encoder = TargetEncoder(cols=categorical_columns)\n",
    "\n",
    "# Fit and transform the categorical columns\n",
    "encoder.fit(X_test[categorical_columns], y)\n",
    "            \n",
    "X_test[categorical_columns] = encoder.transform(X_test[categorical_columns])\n",
    "\n",
    "# Display the DataFrame to check the results\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Dealing with numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X_train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture numerical columns\n",
    "numerical_columns = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical columns\n",
    "scaler.fit(X_train[numerical_columns])\n",
    "\n",
    "X_train[numerical_columns] = scaler.transform(X_train[numerical_columns])\n",
    "\n",
    "# Display the DataFrame to check the results\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture numerical columns\n",
    "numerical_columns = X_test.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the numerical columns\n",
    "scaler.fit(X_test[numerical_columns])\n",
    "\n",
    "X_test[numerical_columns] = scaler.transform(X_test[numerical_columns])\n",
    "\n",
    "# Display the DataFrame to check the results\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8 Concatenate train on one side and test on the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all train\n",
    "df_train = pd.concat([X_train,y_train], axis=1)\n",
    "\n",
    "# Concatenate all test\n",
    "df_test = pd.concat([X_test,y_test], axis=1)\n",
    "\n",
    "# Create a label column\n",
    "df_train['is_test'] = 0\n",
    "df_test['is_test'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9 Concatenate everything in one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed = pd.concat([df_train,df_test], axis=1)\n",
    "data_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Export the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processed.to_excel('df_data_processed.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
